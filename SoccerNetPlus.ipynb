{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMQWfgFHqfKSgDY+p1LOb54"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Environment settings:\n",
        "1. Runtime -> Change runtime type -> GPU\n",
        "2. Put all files into drive directory \"SoccerNetPlus\" and mount the drive to colab (with the next code snippet)"
      ],
      "metadata": {
        "id": "ppdpJ8g8KRL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# interact with drive files\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "rHCyGHbFKUWt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3dfe831-e201-419d-9add-ce6779019437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get input video from YouTube\n",
        "# 1. YouTube id (do an interface like \"https://www.youtube.com/watch?v=\"______________)\n",
        "# 2. start time (eg. 03:20 - minute:second)\n",
        "# 3. end time (eg. 05:40 - minute:second)\n",
        "# 4. video field corners' coordinates"
      ],
      "metadata": {
        "id": "FEVnP3JzSEFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get total time length (in seconds) to convert from user - (ending time - starting time)\n",
        "\n",
        "time_start = 0 # in seconds\n",
        "time_end = 10\n",
        "time_length = time_end - time_start"
      ],
      "metadata": {
        "id": "GtG5MKCwFxZa"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import all libraries\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import load_model\n",
        "from numpy import argmax\n",
        "\n",
        "os.chdir('/content/gdrive/My Drive/SoccerNetPlus/')"
      ],
      "metadata": {
        "id": "Nh6b5Vc7KYJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input preparation\n",
        "\n",
        "# video and its details\n",
        "cap = cv2.VideoCapture('rawdata/video.mp4')\n",
        "if (cap.isOpened() == False): \n",
        "    print(\"Error opening video stream or file\")\n",
        "frames_per_second= int(cap.get(cv2.CAP_PROP_FPS))\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "\n",
        "# pics for the football and the field\n",
        "ballpic = cv2.imread('rawdata/ball.jpg')\n",
        "ground = cv2.imread('rawdata/field.png')\n",
        "details = ballpic.shape[::-1]\n",
        "wt = details[1]\n",
        "ht = details[2]\n",
        "\n",
        "# update time_length from seconds to frames\n",
        "time_start *= frames_per_second\n",
        "time_length *= frames_per_second"
      ],
      "metadata": {
        "id": "KNhpmamLMflC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output preparation\n",
        "\n",
        "out1 = cv2.VideoWriter('match-test.mp4', cv2.VideoWriter_fourcc('M','J','P','G'), 20, (1920,1080))\n",
        "out2 = cv2.VideoWriter('plane-test.mp4', cv2.VideoWriter_fourcc('M','J','P','G'), 20, (900,600))"
      ],
      "metadata": {
        "id": "eGyyhpIm3m9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load models\n",
        "\n",
        "################################################################################\n",
        "# We are taking advantage of the existed, pre-trained model from Yolo v3.\n",
        "# This model is good enough for our \"player detection\" part.\n",
        "# To integrate with OpenCV, we use comprehensive artificial neural networks.\n",
        "# See doc: https://docs.opencv.org/3.4/db/d30/classcv_1_1dnn_1_1Net.html#details\n",
        "################################################################################\n",
        "model = load_model('yolo/model.h5')\n",
        "net = cv2.dnn.readNet(\"yolo/yolov3.weights\", \"yolo/yolov3.cfg\")\n",
        "classes = []\n",
        "with open(\"yolo/coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        "layer_names = net.getLayerNames()\n",
        "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]"
      ],
      "metadata": {
        "id": "T38RijiRNSFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# detect players\n",
        "\n",
        "def get_players(outs, height, width):\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    players = []\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores) # get the index of the maximum values\n",
        "            confidence = scores[class_id]\n",
        "\n",
        "            # eliminate weak predictions\n",
        "            if confidence > 0.5:\n",
        "                # object detected\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "\n",
        "                # rectangle coordinates\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "\n",
        "                # add boxes\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "                \n",
        "    # see doc: https://docs.opencv.org/3.4/d6/d0f/group__dnn.html\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "    for i in range(len(boxes)):\n",
        "        if i in indices:\n",
        "            x, y, w, h = boxes[i]\n",
        "            label = str(classes[class_ids[i]]) # match with yolo\n",
        "            if label == 'person':\n",
        "                players.append(boxes[i])\n",
        "            \n",
        "    return players"
      ],
      "metadata": {
        "id": "n9Wvm8yCNp3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform into 2D plane\n",
        "\n",
        "def plane(players, ball):\n",
        "    curr_ground = ground.copy()\n",
        "\n",
        "    # correspond the field corners from video to pic\n",
        "    pts1 = np.float32([[940,96], [1427,395], [455,395], [943,1022]])\n",
        "    pts2 = np.float32([[450,33], [540,300], [362,302], [450,567]])\n",
        "    matrix = np.array(cv2.getPerspectiveTransform(pts1, pts2))\n",
        "    \n",
        "    for p in players:\n",
        "        x = p[0] + int(p[2] / 2)\n",
        "        y = p[1] + p[3]\n",
        "        pts3 = np.float32([[x,y]])\n",
        "        pts3o = cv2.perspectiveTransform(pts3[None, :, :], matrix)\n",
        "        x1 = int(pts3o[0][0][0])\n",
        "        y1 = int(pts3o[0][0][1])\n",
        "        pp = (x1,y1)\n",
        "        if p[4] == 0:\n",
        "            cv2.circle(curr_ground, pp, 15, (255,0,0), -1)\n",
        "        elif p[4] == 1:\n",
        "            cv2.circle(curr_ground, pp, 15, (255,255,255), -1)\n",
        "        elif p[4] == 2:\n",
        "            #cv2.circle(curr_ground, pp, 15, (0,0,255), -1)\n",
        "            pass\n",
        "\n",
        "    if len(ball) != 0:\n",
        "        xb = ball[0] + int(ball[2] / 2)\n",
        "        yb = ball[1] + int(ball[3] / 2)\n",
        "        pts3ball = np.float32([[xb,yb]])\n",
        "        pts3b = cv2.perspectiveTransform(pts3ball[None, :, :], matrix)\n",
        "        x2 = int(pts3b[0][0][0])\n",
        "        y2 = int(pts3b[0][0][1])\n",
        "        pb = (x2,y2)\n",
        "        cv2.circle(curr_ground, pb, 15, (0,0,0), -1)\n",
        "    return curr_ground"
      ],
      "metadata": {
        "id": "iQrOubnwNjsZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main function\n",
        "\n",
        "while (cap.isOpened() and time_length > 0):\n",
        "    if time_start > 0:\n",
        "        time_start -= 1\n",
        "        continue\n",
        "    \n",
        "    ret, frame = cap.read()\n",
        "    players = []\n",
        "    ball = []\n",
        "    if ret == True :\n",
        "        time_length -= 1\n",
        "\n",
        "        curr_frame = frame.copy()\n",
        "        height, width, channels = frame.shape\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        gray_ball = cv2.cvtColor(ballpic, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        # see doc: https://docs.opencv.org/3.4/d6/d0f/group__dnn.html#ga29f34df9376379a603acd8df581ac8d7\n",
        "        blob = cv2.dnn.blobFromImage(frame, 1/255, (416,416), (0,0,0), True, crop=False)\n",
        "        net.setInput(blob)\n",
        "        outs = net.forward(output_layers)\n",
        "\n",
        "        # players\n",
        "        outs = get_players(outs, height, width)\n",
        "        for i in range(len(outs)):\n",
        "            x, y, w, h = outs[i]\n",
        "            src = frame[y:y+h, x:x+w]\n",
        "            \n",
        "            # some frames are bad and resize function will throw an error\n",
        "            try:\n",
        "                src = cv2.resize(src, (96,96))\n",
        "            except:\n",
        "                continue\n",
        "            \n",
        "            # distinguish judge and players in teams\n",
        "            ym = model.predict(np.reshape(src, (1,96,96,3)))\n",
        "            ym = argmax(ym)\n",
        "            \n",
        "            players.append([x,y,w,h,ym])\n",
        "            \n",
        "            # different colors based on roles and teams\n",
        "            if ym == 0:\n",
        "                cv2.rectangle(curr_frame, (x,y), (x+w, y+h), (0,0,255), 2)\n",
        "            elif ym == 1:\n",
        "                cv2.rectangle(curr_frame, (x,y), (x+w, y+h), (0,255,0), 2)\n",
        "            elif ym == 2:\n",
        "                cv2.rectangle(curr_frame, (x,y), (x+w, y+h), (255,0,0), 2)\n",
        "\n",
        "        # ball\n",
        "        res = cv2.matchTemplate(gray,gray_ball,cv2.TM_SQDIFF_NORMED)\n",
        "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
        "        if min_val < 0.05:\n",
        "            top_left = min_loc\n",
        "            bottom_right = (top_left[0]+wt, top_left[1]+ht)\n",
        "            ball.append(top_left[0])\n",
        "            ball.append(top_left[1])\n",
        "            ball.append(wt)\n",
        "            ball.append(ht)\n",
        "            cv2.rectangle(curr_frame,top_left, bottom_right, (0,255,100), 2)\n",
        "            \n",
        "        # output frame by frame\n",
        "        p = plane(players, ball)\n",
        "        out1.write(curr_frame)\n",
        "        out2.write(p)\n",
        "        #cv2_imshow(curr_frame)\n",
        "        #cv2_imshow(p)\n",
        "        \n",
        "    # press keyboard key 's' to stop\n",
        "    key = cv2.waitKey(1)\n",
        "    if key & 0xFF == ord('s'):\n",
        "        break\n",
        "\n",
        "# release the input and output video\n",
        "cap.release()\n",
        "out1.release()\n",
        "out2.release()\n",
        "\n",
        "# close all the frames\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "vntWXN2UNtgy"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}